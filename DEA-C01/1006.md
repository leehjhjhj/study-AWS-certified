## 1006 (DEA-C01 Review ~100)

### 1. Data Mesh Lake Formation - Redshift Data Share 컬럼별 접근 제어

**문제 시나리오**: 중앙 거버넌스 계정을 가진 데이터 메시에서 Redshift Serverless 테이블 그룹으로 새 데이터 제품 생성. 마케팅 팀과 컴플라이언스 팀에게 서로 다른 컬럼 서브셋으로 공유해야 함.

**정답: B. Create an Amazon Redshift data share + D. Share the Amazon Redshift data share to the Lake Formation catalog**

**A. 왜 Redshift Data Share가 최적인가:**

**컬럼 수준 세분화 공유:**
- **라이브 데이터**: 복사 없이 실시간 데이터 접근
- **세분화된 권한**: 테이블별, 컬럼별 접근 제어
- **크로스 계정**: 여러 AWS 계정 간 안전한 데이터 공유

**아키텍처:**
```
Central Governance Account
├── Lake Formation (중앙 카탈로그)
├── Redshift Serverless
│   └── Data Share 1 (Marketing): customer_data (id, name, email)
│   └── Data Share 2 (Compliance): customer_data (id, ssn, tax_id)
│
├── Marketing Account → 마케팅 컬럼만 접근
└── Compliance Account → 규정준수 컬럼만 접근
```

**B. Data Share 구현 예시:**

```sql
-- 마케팅 팀용 Data Share
CREATE DATASHARE marketing_data_share;
ALTER DATASHARE marketing_data_share
ADD TABLE customer_data (customer_id, name, email, purchase_history);

-- 컴플라이언스 팀용 Data Share
CREATE DATASHARE compliance_data_share;
ALTER DATASHARE compliance_data_share
ADD TABLE customer_data (customer_id, ssn, tax_id, kyc_status);
```

**C. Lake Formation 통합:**

```python
import boto3

lakeformation_client = boto3.client('lakeformation')

# Data Share를 Lake Formation에 등록
lakeformation_client.register_resource(
    ResourceArn='arn:aws:redshift:region:account:datashare:cluster/marketing-data-share',
    UseServiceLinkedRole=True
)

# 권한 부여
lakeformation_client.grant_permissions(
    Principal={'DataLakePrincipalIdentifier': 'arn:aws:iam::marketing-account:root'},
    Resource={'Database': {'Name': 'marketing_datashare_db'}},
    Permissions=['SELECT']
)
```

**D. 다른 솔루션들이 부적절한 이유:**

**A. Lake Formation만 사용:**
- **컬럼 제어 한계**: 동일 테이블의 서로 다른 컬럼 서브셋 제공 복잡
- **Redshift 기능 미활용**: Data Share의 네이티브 성능 이점 못활용

**C. S3 Export + 별도 데이터셋:**
- **데이터 복제**: 불필요한 저장 비용 증가
- **동기화 문제**: 실시간 변경사항 반영 안됨

**E. 크로스 계정 직접 접근:**
- **보안 위험**: 세분화된 권한 제어 어려움
- **거버넌스 부재**: 중앙 카탈로그 및 감사 기능 활용 불가

---

### 2. QuickSight 크로스 계정 S3 접근 - KMS 키 권한 설정

**문제 시나리오**: 회사가 Hub-Account의 S3 버킷(KMS 암호화)에 데이터를 저장하고, 별도 BI-Account의 QuickSight로 시각화를 생성함. S3 버킷 정책은 이미 QuickSight 서비스 역할에 접근 권한을 부여했으나, 크로스 계정 접근을 완전히 활성화해야 함.

**정답: D. Add an IAM policy to the QuickSight service role to give QuickSight access to the KMS key + E. Add the KMS key as a resource that the QuickSight service role can access**

**A. 왜 KMS 키 권한이 필요한가:**

**암호화된 S3 객체 접근 요구사항:**
- **S3 버킷 접근**: 이미 버킷 정책으로 해결됨
- **KMS 키 접근**: 암호화된 객체 복호화를 위해 필수
- **크로스 계정**: 서로 다른 계정 간 KMS 키 공유 필요

**아키텍처:**
```
Hub-Account                    BI-Account
├── S3 Bucket (data)          ├── QuickSight
├── KMS Key (encryption)      └── QuickSight Service Role
└── Bucket Policy ✓               └── KMS Policy 필요 ✗
```

**B. KMS 권한 구현:**

```json
// Hub-Account의 KMS 키 정책
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowQuickSightCrossAccountAccess",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::BI-Account:role/aws-quicksight-service-role"
      },
      "Action": [
        "kms:Decrypt",
        "kms:DescribeKey",
        "kms:GenerateDataKey"
      ],
      "Resource": "*"
    }
  ]
}
```

```json
// BI-Account의 QuickSight 서비스 역할 정책
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "kms:Decrypt",
        "kms:DescribeKey"
      ],
      "Resource": "arn:aws:kms:region:Hub-Account:key/key-id"
    }
  ]
}
```

**C. 다른 솔루션들이 부적절한 이유:**

**A. S3 버킷 정책만 수정:**
- **암호화 미고려**: KMS 키 접근 권한 없이는 암호화된 객체 읽기 불가
- **복호화 실패**: 데이터 접근 시 권한 오류 발생

**B. QuickSight 계정에 버킷 복사:**
- **데이터 중복**: 불필요한 저장 비용 및 동기화 문제
- **보안 위험**: 데이터 거버넌스 복잡도 증가

**C. 퍼블릭 접근 활성화:**
- **보안 취약**: 데이터 노출 위험
- **규정 위반**: 기업 보안 정책 위배

---

### 3. Kinesis KPL/KCL 중복 데이터 - Producer 재시도와 Resharding 이슈

**문제 시나리오**: 재고 관리 시스템(KPL 사용)과 자동 재주문 시스템(KCL 사용)이 Kinesis Data Streams를 통해 연결됨. 스트림이 자동 스케일링 설정되어 있는데, 재주문 시스템에서 중복 데이터를 수신하는 문제 발생.

**정답: A. The producer experienced network-related timeouts + C. There was a change in the number of shards, record processors, or both**

**A. 왜 네트워크 타임아웃이 중복을 발생시키는가:**

**KPL 재시도 메커니즘:**
- **네트워크 타임아웃**: 응답을 받지 못한 요청을 실패로 판단
- **자동 재시도**: KPL이 같은 레코드를 다시 전송
- **실제 처리됨**: 첫 번째 요청이 실제로는 성공했을 경우

**아키텍처:**
```
KPL Producer → [네트워크 지연] → Kinesis → KCL Consumer
     ↓ (타임아웃)                        ↓
   재시도 전송 → → → → → → → → → → → 중복 수신
```

**B. 왜 Shard 변경이 중복을 발생시키는가:**

**KCL Resharding 처리:**
- **Shard 분할/병합**: 스트림 스케일링 시 shard 구조 변경
- **Checkpoint 누락**: 진행 상태 저장 실패 가능성
- **레코드 재처리**: 새로운 shard iterator로 인한 이전 레코드 재소비

**Resharding 시나리오:**
```python
# Shard 변경 전
shard-000001: [record1, record2, record3] ← checkpoint: record2

# Shard 분할 후
shard-000001: [record1, record2] (closed)
shard-000002: [record3, record4, record5]

# KCL 재시작 시 checkpoint 손실로 record2부터 재처리
```

**C. 중복 방지 구현:**

```python
# Producer 측 - 멱등성 키 사용
import uuid

def send_inventory_update(kpl_producer, item_data):
    # 고유 식별자로 중복 방지
    idempotency_key = f"{item_data['item_id']}_{item_data['timestamp']}"

    kpl_producer.add_user_record(
        stream_name="inventory-stream",
        partition_key=item_data['item_id'],
        data=json.dumps({
            **item_data,
            'idempotency_key': idempotency_key
        })
    )

# Consumer 측 - 중복 제거 로직
def process_record(record):
    data = json.loads(record['Data'])
    idempotency_key = data['idempotency_key']

    # DynamoDB를 사용한 중복 확인
    try:
        dynamodb.put_item(
            TableName='processed_records',
            Item={'id': idempotency_key, 'processed_at': datetime.now()},
            ConditionExpression='attribute_not_exists(id)'
        )

        # 새로운 레코드인 경우만 처리
        process_inventory_update(data)

    except ClientError as e:
        if e.response['Error']['Code'] == 'ConditionalCheckFailedException':
            print(f"Duplicate record ignored: {idempotency_key}")
```

**D. 다른 옵션들이 틀린 이유:**

**B. KCL 버전 불일치:**
- **기능적 문제**: 버전 불일치는 호환성 문제를 일으키지만 중복과는 무관
- **중복 원인 아님**: 데이터 중복보다는 파싱 오류나 기능 제한 발생

**D. Partition Key 분배:**
- **성능 문제**: 핫 파티션 발생 가능하지만 중복 데이터와는 무관
- **처리 순서**: 같은 파티션 내에서는 순서 보장됨

**E. 복원력 구현:**

```python
# KCL Consumer에서 체크포인트 관리
class InventoryRecordProcessor:
    def process_records(self, records, checkpointer):
        processed_count = 0

        for record in records:
            try:
                if not is_duplicate(record):
                    process_inventory_record(record)
                    processed_count += 1

                # 10개마다 체크포인트 저장
                if processed_count % 10 == 0:
                    checkpointer.checkpoint()

            except Exception as e:
                logging.error(f"Failed to process record: {e}")
                # 실패한 레코드는 DLQ로 전송
                send_to_dlq(record)

        # 배치 완료 후 최종 체크포인트
        checkpointer.checkpoint()
```

---

이 문서는 DEA-C01 1006일자 문제들의 오답노트입니다. Data Mesh, 크로스 계정 접근, Kinesis 중복 데이터 처리를 다룹니다.

### 4. AWS Glue Data Catalog 증분 업데이트 - S3 이벤트 기반 자동화

**문제 시나리오**: 데이터 엔지니어가 S3 버킷의 데이터에 대한 Glue Data Catalog를 구성하고, 증분 업데이트를 받도록 설정해야 함. S3 버킷 이벤트 알림과 SQS 큐는 이미 설정되어 있으며, 최소 운영 오버헤드로 요구사항을 충족해야 함.

**정답: A. Create an S3 event-based AWS Glue crawler + C. Use an AWS Lambda function to directly update the Data Catalog**

**A. 왜 S3 이벤트 기반 Crawler가 최적인가:**

**자동화된 스키마 감지:**
- **이벤트 트리거**: S3 객체 생성/수정 시 자동 실행
- **스키마 진화**: 새로운 컬럼이나 데이터 타입 변경 자동 감지
- **최소 설정**: 추가 코드 작성 없이 GUI로 간단 설정

**아키텍처:**
```
S3 Bucket → S3 Event → SQS Queue → Glue Crawler
    ↓                               ↓
  새 파일            자동 트리거    Data Catalog 업데이트
```

**B. Lambda를 통한 직접 업데이트 장점:**

**세밀한 제어:**
- **즉시 반영**: 파일 업로드 즉시 카탈로그 업데이트
- **커스텀 로직**: 비즈니스 규칙에 따른 선택적 업데이트
- **효율성**: 전체 크롤링 없이 변경된 부분만 처리

**구현 예시:**

```python
import boto3
import json

def lambda_handler(event, context):
    glue_client = boto3.client('glue')

    for record in event['Records']:
        # SQS 메시지에서 S3 이벤트 파싱
        s3_event = json.loads(record['body'])

        for s3_record in s3_event['Records']:
            bucket = s3_record['s3']['bucket']['name']
            key = s3_record['s3']['object']['key']

            # 파티션 추출 (예: year=2024/month=10/day=06/file.parquet)
            partition_values = extract_partition_values(key)

            if partition_values:
                # 새 파티션 추가
                add_partition_to_catalog(glue_client, bucket, key, partition_values)
            else:
                # 테이블 메타데이터 업데이트
                update_table_metadata(glue_client, bucket, key)

def extract_partition_values(s3_key):
    # 파티션 패턴 매칭 (year=2024/month=10/day=06/)
    import re
    pattern = r'year=(\d+)/month=(\d+)/day=(\d+)/'
    match = re.search(pattern, s3_key)

    if match:
        return {
            'year': match.group(1),
            'month': match.group(2),
            'day': match.group(3)
        }
    return None

def add_partition_to_catalog(glue_client, bucket, key, partition_values):
    try:
        glue_client.create_partition(
            DatabaseName='sales_data',
            TableName='daily_transactions',
            PartitionInput={
                'Values': [
                    partition_values['year'],
                    partition_values['month'],
                    partition_values['day']
                ],
                'StorageDescriptor': {
                    'Location': f's3://{bucket}/{"/".join(key.split("/")[:-1])}/',
                    'InputFormat': 'org.apache.hadoop.mapred.TextInputFormat',
                    'OutputFormat': 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',
                    'SerdeInfo': {
                        'SerializationLibrary': 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
                    }
                }
            }
        )
        print(f"Partition added: {partition_values}")
    except glue_client.exceptions.AlreadyExistsException:
        print(f"Partition already exists: {partition_values}")
```

**C. 두 방법의 조합 전략:**

**이벤트 기반 Crawler:**
- **스키마 변경**: 새로운 테이블이나 컬럼 구조 변경 시
- **주기적 검증**: 데이터 무결성 확인

**Lambda 직접 업데이트:**
- **파티션 추가**: 새로운 날짜별 파티션 즉시 반영
- **메타데이터 갱신**: 파일 크기, 레코드 수 등 통계 정보

**D. 다른 솔루션들이 부적절한 이유:**

**B. 스케줄된 Crawler:**
- **지연 발생**: 실시간 업데이트 불가
- **리소스 낭비**: 변경사항 없어도 전체 스캔 수행

**D. EventBridge + Step Functions:**
- **복잡성 증가**: 단순한 업데이트에 과도한 오케스트레이션
- **운영 오버헤드**: 여러 서비스 모니터링 및 관리 필요

**E. 운영 최적화:**

```python
# SQS 배치 처리로 효율성 향상
def process_sqs_batch(event, context):
    processed_partitions = set()

    for record in event['Records']:
        partition_key = extract_partition_key(record)

        # 중복 파티션 처리 방지
        if partition_key not in processed_partitions:
            update_catalog_partition(partition_key)
            processed_partitions.add(partition_key)

    # 배치 처리 완료 후 Crawler 트리거 (스키마 검증용)
    if len(processed_partitions) > 10:
        trigger_validation_crawler()
```

---


### 5. Athena CloudTrail 로그 쿼리 문제 - 파티션 및 경로 검증

**문제 시나리오**: 회사가 S3 데이터 레이크에 여러 애플리케이션의 CloudTrail 로그를 수집하고, Glue로 카탈로그화하며 연도별로 파티셔닝함. Athena로 분석 중인데 특정 테이블 쿼리에서 데이터가 반환되지 않는 문제 발생.

**정답: A. Confirm that Athena is pointing to the correct Amazon S3 location + C. Use the MSCK REPAIR TABLE command**

**A. 왜 S3 위치 확인이 필요한가:**

**테이블 정의 오류:**
- **잘못된 S3 경로**: 테이블 생성 시 올바르지 않은 location 설정
- **버킷 변경**: CloudTrail 로그 저장 위치가 변경되었을 경우
- **권한 문제**: Athena가 해당 S3 위치에 접근할 수 없음

**B. 왜 MSCK REPAIR TABLE이 필요한가:**

**파티션 메타데이터 동기화:**
- **누락된 파티션**: S3에는 존재하지만 Glue 카탈로그에 등록되지 않은 파티션
- **자동 검색**: S3 디렉토리 구조를 스캔하여 파티션 자동 추가
- **연도별 파티션**: 새로운 연도 디렉토리가 생성되었지만 카탈로그에 반영 안됨

**C. 트러블슈팅 절차:**

**1단계: S3 위치 검증**
```sql
-- 테이블 정의 확인
DESCRIBE FORMATTED cloudtrail_logs;

-- S3 경로가 실제 데이터 위치와 일치하는지 확인
SHOW CREATE TABLE cloudtrail_logs;
```

**2단계: 파티션 복구**
```sql
-- 파티션 현황 확인
SHOW PARTITIONS cloudtrail_logs;

-- 누락된 파티션 자동 추가
MSCK REPAIR TABLE cloudtrail_logs;

-- 복구 후 파티션 재확인
SHOW PARTITIONS cloudtrail_logs;
```

**D. 다른 옵션들이 부적절한 이유:**

**B. 다른 AWS 계정에서 접근:**
- **권한 복잡성**: 크로스 계정 설정은 단순한 쿼리 문제와 무관
- **근본 해결 아님**: S3 위치나 파티션 문제를 해결하지 못함

**D. CloudTrail 설정 변경:**
- **로그 생성 문제**: 기존 데이터가 있다면 CloudTrail 설정과 무관
- **과도한 조치**: 단순 쿼리 문제에 대한 과도한 대응

**E. 예방 조치:**

**자동화된 모니터링:**
- CloudWatch 메트릭으로 쿼리 성공률 추적
- 정기적인 파티션 상태 점검
- S3 이벤트 기반 자동 파티션 추가

---

### 6. Redshift JSON 데이터 로딩 - SUPER 데이터 타입 활용

**문제 시나리오**: 회사가 제3자로부터 받은 고객 데이터를 Redshift 데이터 웨어하우스에 로드해야 함. 주문 데이터와 제품 데이터도 같은 웨어하우스에 저장되어 있으며, 결합된 데이터셋으로 잠재 고객을 식별하려고 함. 소스 데이터의 한 필드가 JSON 형식의 값을 포함하고 있음.

**정답: A. Use the SUPER data type to store the data in the Amazon Redshift table**

**A. 왜 SUPER 데이터 타입이 최적인가:**

**최소 노력 (LEAST effort) 달성:**
- **스키마 변경 불필요**: JSON 구조가 변경되어도 테이블 수정 없음
- **직접 저장**: JSON을 파싱하거나 평면화할 필요 없음
- **네이티브 지원**: Redshift에서 JSON 쿼리를 직접 지원

**SUPER 타입의 장점:**
- **스키마리스**: 복잡하고 중첩된 JSON 구조 그대로 저장
- **쿼리 최적화**: Redshift 엔진이 JSON 경로 액세스 최적화
- **데이터 압축**: 효율적인 저장 공간 활용

**B. 사용 예시:**

```sql
-- 테이블 생성
CREATE TABLE customer_data (
    customer_id INTEGER,
    name VARCHAR(100),
    email VARCHAR(100),
    profile_data SUPER  -- JSON 데이터 저장
);

-- 데이터 로드
COPY customer_data FROM 's3://bucket/customer-data/'
JSON 'auto' GZIP;

-- JSON 데이터 쿼리
SELECT
    customer_id,
    name,
    profile_data.address.city,
    profile_data.preferences[0].category
FROM customer_data
WHERE profile_data.age > 25;
```

**C. 다른 솔루션들이 부적절한 이유:**

**B. JSON을 별도 테이블로 분리:**
- **복잡성 증가**: 여러 테이블 간 조인 필요
- **더 많은 노력**: 스키마 설계 및 ETL 파이프라인 구축 필요

**C. JSON을 VARCHAR로 저장:**
- **쿼리 비효율**: JSON 파싱 함수를 매번 사용해야 함
- **인덱싱 불가**: JSON 내부 필드에 대한 최적화 없음

**D. 사전 평면화:**
- **스키마 고정**: JSON 구조 변경 시 테이블 수정 필요
- **ETL 복잡도**: 추가적인 변환 로직 구현 필요

**D. 실제 활용 시나리오:**

**고객 세분화 쿼리:**
```sql
-- 잠재 고객 식별
SELECT DISTINCT c.customer_id, c.name
FROM customer_data c
JOIN order_data o ON c.customer_id = o.customer_id
WHERE c.profile_data.interests @> '["electronics"]'
  AND o.total_amount > 1000;
```

**JSON 데이터 분석:**
- **동적 속성**: 고객별로 다른 속성 집합 처리
- **중첩 구조**: 복잡한 프로필 데이터 직접 쿼리
- **배열 처리**: 관심사, 구매 이력 등 배열 데이터 분석

---

### 7. Redshift PII 데이터 접근 제어 - Dynamic Data Masking

**문제 시나리오**: 회사가 PII가 포함된 고객 데이터를 Redshift 클러스터에 저장함. 마케팅 팀(클레임 정보는 난독화, 연락처는 전체 접근), 클레임 팀(처리하는 클레임의 고객 정보 접근), 분석 팀(PII 데이터만 난독화 접근)이 각각 다른 접근 권한이 필요함.

**정답: C. Create a separate Amazon Redshift database role for each team. Define masking policies that apply for each team separately**

**A. 왜 Dynamic Data Masking이 최적인가:**

**최소 관리 오버헤드 (LEAST administrative overhead):**
- **단일 데이터 소스**: 데이터를 이동하지 않고 Redshift 내에서 처리
- **정책 기반**: 역할별로 자동 적용되는 마스킹 정책
- **중앙 관리**: 하나의 시스템에서 모든 접근 제어 관리

**Dynamic Data Masking 장점:**
- **실시간 적용**: 쿼리 실행 시 자동으로 마스킹 적용
- **데이터 중복 없음**: 원본 데이터는 그대로 유지
- **유연한 정책**: 팀별, 컬럼별 세분화된 마스킹 규칙

**B. 팀별 접근 제어 구현:**

**마케팅 팀 정책:**
```sql
-- 클레임 정보는 마스킹, 연락처는 전체 접근
CREATE MASKING POLICY marketing_policy AS (val varchar(256))
RETURNS varchar(256) ->
  CASE
    WHEN current_role() = 'marketing_role' AND column_name = 'claim_amount'
    THEN 'XXX-MASKED-XXX'
    ELSE val
  END;
```

**분석 팀 정책:**
```sql
-- PII 데이터만 마스킹
CREATE MASKING POLICY analytics_policy AS (val varchar(256))
RETURNS varchar(256) ->
  CASE
    WHEN current_role() = 'analytics_role' AND column_name IN ('ssn', 'phone', 'email')
    THEN regexp_replace(val, '.', '*', 1, length(val)-4)
    ELSE val
  END;
```

**C. 다른 솔루션이 부적절한 이유:**

**D. Lake Formation 이전:**
- **데이터 이동**: 추가적인 ETL 파이프라인 필요
- **중복 저장**: S3와 Redshift 양쪽에 데이터 유지
- **복잡성 증가**: 두 시스템 간 동기화 및 거버넌스 관리

**A/B. 별도 뷰나 테이블:**
- **관리 복잡도**: 팀별로 여러 개의 뷰/테이블 생성 및 유지
- **데이터 일관성**: 원본 데이터 변경 시 모든 뷰 업데이트 필요
- **확장성 부족**: 새로운 팀이나 정책 추가 시 수동 작업 필요

**D. 운영상 이점:**

**중앙집중식 관리:**
- **정책 변경**: 마스킹 정책만 수정하면 모든 사용자에게 자동 적용
- **감사 추적**: 단일 시스템에서 모든 접근 기록 추적
- **성능 최적화**: 추가적인 데이터 이동이나 변환 없음

**확장성:**
- **새로운 팀**: 역할과 정책만 추가하면 즉시 적용
- **정책 조정**: 비즈니스 요구사항 변경 시 빠른 대응
- **규정 준수**: 일관된 데이터 보호 정책 적용

---

### 8. Redshift 테이블 분산 스타일 - AUTO Distribution

**문제 시나리오**: 회사가 Redshift를 데이터 웨어하우스로 사용하며, 데이터 엔지니어가 물리적 데이터 모델을 설계해야 함. 비정규화된 테이블이 크기가 계속 증가하고 있는데, 분산 키로 사용할 적절한 컬럼이 없음. 최소 유지보수 오버헤드로 요구사항을 충족해야 함.

**정답: C. AUTO distribution**

**A. 왜 AUTO Distribution이 최적인가:**

**최소 유지보수 오버헤드 (LEAST maintenance overhead):**
- **자동 최적화**: Redshift가 테이블 크기와 쿼리 패턴을 분석하여 자동 결정
- **동적 조정**: 데이터 증가에 따라 분산 전략 자동 변경
- **관리 불필요**: 수동으로 분산 키나 전략을 선택할 필요 없음

**AUTO Distribution의 동작:**
- **작은 테이블**: ALL distribution 적용 (모든 노드에 복제)
- **중간 테이블**: EVEN distribution 적용 (균등 분산)
- **큰 테이블**: 적절한 컬럼을 찾아 KEY distribution 시도

**B. 적절한 분산 키가 없는 상황에서의 이점:**

**지능적 선택:**
- **통계 분석**: 쿼리 패턴과 조인 빈도 분석
- **성능 모니터링**: 실제 쿼리 성능을 기반으로 최적화
- **자동 전환**: 테이블 성장에 따른 최적 전략 자동 변경

**유지보수 부담 최소화:**
- **모니터링 자동화**: 분산 성능 지속적 추적
- **재배치 자동화**: 필요시 자동으로 데이터 재분산
- **최적화 권장**: 더 나은 분산 전략 자동 제안

**C. 다른 Distribution 스타일이 부적절한 이유:**

**A. ALL Distribution:**
- **저장 공간 낭비**: 모든 노드에 전체 데이터 복제
- **대용량 부적합**: 테이블 크기가 계속 증가하는 상황에 비효율적
- **노드 확장 제약**: 클러스터 확장 시 저장 공간 부족

**B. EVEN Distribution:**
- **조인 성능 저하**: 관련 데이터가 다른 노드에 분산되어 조인 비용 증가
- **고정된 전략**: 데이터 특성 변화에 대응하지 못함
- **최적화 부재**: 쿼리 패턴을 고려하지 않는 단순 분산

**D. KEY Distribution:**
- **적절한 키 부재**: 문제에서 명시적으로 적절한 분산 키가 없다고 함
- **핫스팟 위험**: 잘못된 키 선택 시 특정 노드에 데이터 집중
- **수동 관리 필요**: 키 선택 및 성능 모니터링 필요

**D. AUTO Distribution의 실제 동작:**

**단계별 최적화:**
1. **초기 단계**: 작은 테이블로 ALL distribution 적용
2. **성장 단계**: 중간 크기로 EVEN distribution 전환
3. **성숙 단계**: 최적 컬럼 발견 시 KEY distribution 적용

**성능 모니터링:**
- **쿼리 패턴 분석**: 자주 사용되는 조인 컬럼 식별
- **데이터 스큐 감지**: 불균등 분산 방지
- **자동 권장사항**: 더 나은 분산 전략 제안

---

### 9. Amazon Neptune 그래프 애플리케이션 개발 - Gremlin과 SPARQL

**문제 시나리오**: 데이터 엔지니어가 Amazon Neptune을 사용하여 그래프 애플리케이션을 개발해야 함. 그래프 애플리케이션 개발에 사용해야 할 프로그래밍 언어를 선택해야 함.

**정답: A. Gremlin + D. SPARQL**

**A. 왜 Gremlin이 필요한가:**

**Property Graph 모델 지원:**
- **Apache TinkerPop**: 표준 그래프 순회 언어
- **노드와 엣지**: 속성을 가진 그래프 구조 쿼리
- **복잡한 순회**: 다단계 그래프 탐색 및 패턴 매칭

**Gremlin 활용 사례:**
- **소셜 네트워크**: 친구 관계, 추천 시스템
- **사기 탐지**: 의심스러운 거래 패턴 분석
- **지식 그래프**: 엔티티 간 관계 탐색

**B. 왜 SPARQL이 필요한가:**

**RDF 그래프 모델 지원:**
- **W3C 표준**: 시맨틱 웹 쿼리 언어
- **트리플 스토어**: Subject-Predicate-Object 구조
- **온톨로지**: 의미론적 관계 표현

**SPARQL 활용 사례:**
- **시맨틱 데이터**: 의료, 생명과학 데이터
- **링크드 데이터**: 웹 상의 구조화된 데이터
- **온톨로지 쿼리**: 개념 간 계층 관계 분석

**C. Neptune의 이중 엔진 아키텍처:**

**Property Graph Engine:**
- **Gremlin 지원**: Apache TinkerPop 호환
- **높은 성능**: 복잡한 그래프 순회 최적화
- **유연한 스키마**: 동적 속성 추가 가능

**RDF Engine:**
- **SPARQL 지원**: W3C 표준 완전 구현
- **추론 엔진**: 온톨로지 기반 추론 지원
- **표준 준수**: 시맨틱 웹 생태계 완전 호환

**D. 다른 옵션들이 부적절한 이유:**

**B. SQL:**
- **관계형 모델**: 그래프 관계 표현에 부적합
- **조인 복잡성**: 다단계 관계 쿼리 시 성능 저하
- **Neptune 미지원**: Neptune은 SQL 인터페이스 제공하지 않음

**C. Cypher:**
- **Neo4j 전용**: Neptune에서 네이티브 지원하지 않음
- **벤더 종속**: 특정 그래프 데이터베이스에 한정
- **호환성 부족**: Neptune의 표준 인터페이스와 불일치

**E. GraphQL:**
- **API 쿼리 언어**: 그래프 데이터베이스 쿼리 언어가 아님
- **클라이언트 중심**: 서버 측 데이터 조작에 부적합
- **Neptune 미지원**: 직접적인 Neptune 인터페이스 없음

**E. 실제 개발 시나리오:**

**Gremlin 사용 예:**
- 소셜 네트워크에서 2단계 친구 찾기
- 추천 시스템에서 유사한 사용자 패턴 분석
- 공급망에서 영향도 분석

**SPARQL 사용 예:**
- 의료 온톨로지에서 질병-약물 관계 쿼리
- 지식 베이스에서 개념 계층 탐색
- 링크드 데이터에서 교차 참조 분석

**개발 도구 통합:**
- **다양한 SDK**: Python, Java, JavaScript 등 지원
- **Notebook 통합**: Jupyter에서 직접 쿼리 실행
- **시각화 도구**: 그래프 구조 시각적 분석

---

### 10. S3 Object Lock - Compliance Mode로 데이터 보호

**문제 시나리오**: 회사가 고객 기록을 Amazon S3에 저장하며, 각 기록이 생성된 후 7년간 삭제나 수정이 불가능해야 함. 루트 사용자도 데이터를 삭제하거나 수정할 수 없어야 함. 데이터 엔지니어가 S3 Object Lock을 사용하여 데이터를 보호하려고 함.

**정답: B. Enable compliance mode on the S3 bucket. Use a default retention period of 7 years**

**A. 왜 Compliance Mode가 필요한가:**

**절대적 보호 (루트 사용자 포함):**
- **변경 불가**: 어떤 사용자도 보유 기간 중 객체 삭제/수정 불가
- **루트 제한**: 루트 사용자도 보호 설정을 무시할 수 없음
- **규정 준수**: 법적/규제 요구사항에 대한 완전한 보장

**Compliance Mode 특징:**
- **완전 잠금**: 보유 기간 동안 객체 완전 보호
- **설정 불변**: 한 번 설정되면 보유 기간 단축 불가
- **권한 무관**: 어떤 IAM 권한으로도 무시 불가

**B. Governance Mode가 부적절한 이유:**

**우회 가능성:**
- **특별 권한**: s3:BypassGovernanceRetention 권한으로 우회 가능
- **루트 접근**: 루트 사용자가 보호 설정 무시 가능
- **유연성**: 비즈니스 필요에 따른 조기 삭제 허용

**보안 요구사항 미충족:**
- **규제 위반 위험**: 법적 요구사항을 완전히 보장하지 못함
- **내부 위협**: 권한을 가진 사용자의 실수나 악의적 행동 방지 불가

**C. S3 Object Lock 구성:**

**기본 설정:**
- **버킷 레벨**: 모든 새 객체에 자동 적용
- **7년 보유**: 객체 생성일로부터 정확히 7년간 보호
- **WORM**: Write Once Read Many 모델 구현

**객체 수준 제어:**
- **개별 설정**: 특정 객체에 다른 보유 기간 적용 가능
- **Legal Hold**: 법적 분쟁 시 무기한 보호 추가
- **버전 관리**: 각 객체 버전별 독립적 보호

**D. 실제 적용 시나리오:**

**규제 업계:**
- **금융**: 고객 거래 기록 보존
- **의료**: 환자 기록 법정 보존 기간
- **법무**: 계약서 및 법적 문서 보관

**운영 고려사항:**
- **스토리지 비용**: 7년간 지속적 보관 비용
- **백업 전략**: 추가 보호를 위한 교차 리전 복제
- **모니터링**: 보유 기간 만료 추적 및 자동화

**E. 다른 옵션들과 비교:**

**Legal Hold vs Retention:**
- **Legal Hold**: 무기한 보호, 법적 절차 완료 시까지
- **Retention**: 고정 기간 보호, 자동 만료

**Cross-Region 고려:**
- **복제 보호**: 다른 리전에도 동일한 보호 적용
- **재해 복구**: 물리적 재해 시에도 데이터 보존 보장

---

### 11. AWS Glue 데이터 품질 평가 - DQDL 기반 자동화

**문제 시나리오**: 회사가 S3 데이터 레이크를 보유하고, AWS Glue로 데이터 카탈로그를 관리하며 Glue Studio로 ETL 파이프라인을 구현함. 파이프라인이 실행될 때마다 데이터 품질 문제를 확인해야 하며, 사전 정의된 임계값 기반으로 데이터 품질 규칙을 평가해야 함.

**정답: B. Add a new Evaluate Data Quality transform to each Glue ETL job. Use Data Quality Definition Language (DQDL) to implement a ruleset**

**A. 왜 Evaluate Data Quality Transform이 최적인가:**

**최소 구현 노력 (LEAST implementation effort):**
- **네이티브 통합**: Glue Studio에서 드래그 앤 드롭으로 추가
- **기존 파이프라인**: 현재 ETL 작업에 단순히 노드만 추가
- **코드 작성 불필요**: GUI 기반 설정으로 완전 구현

**DQDL (Data Quality Definition Language) 장점:**
- **표준화된 규칙**: 선언적 언어로 품질 규칙 정의
- **다양한 검증**: 완전성, 정확성, 일관성, 유효성 검사
- **임계값 설정**: 사전 정의된 기준에 따른 자동 평가

**B. DQDL 규칙 예시:**

**완전성 검사:**
```
Rules = [
    Completeness "customer_id" > 0.95,
    Completeness "email" > 0.90,
    ColumnCount > 50000
]
```

**데이터 유효성:**
```
Rules = [
    ColumnValues "email" matches "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}",
    ColumnValues "age" between 18 and 120,
    CustomSql "SELECT COUNT(*) FROM primary_frame WHERE order_amount < 0" = 0
]
```

**C. 통합 및 자동화:**

**파이프라인 통합:**
- **Transform 노드**: ETL 흐름 중간에 삽입
- **조건부 실행**: 품질 평가 결과에 따른 후속 처리
- **실패 처리**: 임계값 미달 시 파이프라인 중단 또는 알림

**모니터링 및 알림:**
- **CloudWatch 메트릭**: 품질 점수 자동 전송
- **SNS 알림**: 품질 임계값 위반 시 즉시 알림
- **대시보드**: 품질 트렌드 시각화

**D. 다른 솔루션들이 부적절한 이유:**

**A. 커스텀 Lambda 함수:**
- **개발 복잡도**: 품질 검증 로직 처음부터 구현 필요
- **유지보수**: 규칙 변경 시 코드 수정 및 배포 필요
- **통합 어려움**: Glue ETL과 별도 시스템으로 관리

**C. 외부 데이터 품질 도구:**
- **추가 비용**: 서드파티 솔루션 라이선스 비용
- **복잡한 통합**: AWS 생태계 외부 도구 연동
- **벤더 종속**: 특정 업체에 대한 의존성

**D. Step Functions 오케스트레이션:**
- **과도한 복잡도**: 단순한 품질 검사에 과도한 워크플로우
- **관리 오버헤드**: 추가적인 상태 기계 관리 필요

**E. 실제 구현 시나리오:**

**품질 게이트웨이:**
- **1차 검증**: 기본 스키마 및 완전성 확인
- **2차 검증**: 비즈니스 규칙 기반 유효성 검사
- **3차 검증**: 교차 참조 및 일관성 검사

**운영 워크플로우:**
- **성공 시**: 다음 ETL 단계 진행
- **경고 시**: 알림 발송 후 처리 계속
- **실패 시**: 파이프라인 중단 및 복구 절차 실행

**품질 메트릭 추적:**
- **이력 관리**: 시간별 품질 점수 변화 추적
- **트렌드 분석**: 데이터 품질 저하 패턴 식별
- **SLA 모니터링**: 품질 서비스 수준 목표 달성도 측정

---

### 12. EKS 마이크로서비스 모니터링 - FluentBit, OpenTelemetry, OpenSearch

**문제 시나리오**: 회사가 마이크로서비스 아키텍처 애플리케이션을 Amazon EKS 클러스터에서 호스팅함. 강력한 모니터링 시스템을 구축하고, EKS 클러스터와 애플리케이션의 로그를 분석해야 함. 전체 애플리케이션 요청 흐름에서 실패 지점을 식별하기 위해 클러스터 로그와 애플리케이션 트레이스를 연관시켜야 함.

**정답: A. Use FluentBit to collect logs. Use OpenTelemetry to collect traces + D. Use Amazon OpenSearch to correlate the logs and traces**

**A. 왜 FluentBit과 OpenTelemetry가 필요한가:**

**최소 개발 노력 (LEAST development effort):**
- **표준 도구**: 업계 표준 오픈소스 솔루션
- **EKS 통합**: AWS에서 공식 지원하는 로깅/추적 도구
- **설정 기반**: 코드 변경 최소화, 설정 파일로 구성

**FluentBit 장점:**
- **경량**: 낮은 리소스 사용량으로 모든 노드에서 실행
- **다양한 출력**: OpenSearch, CloudWatch, S3 등 지원
- **실시간 처리**: 스트리밍 로그 수집 및 전송

**OpenTelemetry 장점:**
- **벤더 중립**: 다양한 백엔드 시스템 지원
- **자동 계측**: 최소한의 코드 변경으로 트레이스 수집
- **통합 표준**: 메트릭, 로그, 트레이스 통합 수집

**B. 왜 Amazon OpenSearch가 필요한가:**

**통합 상관관계 분석:**
- **단일 플랫폼**: 로그와 트레이스를 하나의 시스템에서 검색
- **강력한 쿼리**: Elasticsearch 기반의 복합 검색 기능
- **시각화**: Kibana 대시보드로 상관관계 시각화

**실시간 분석:**
- **인덱싱**: 실시간 로그/트레이스 데이터 인덱싱
- **알림**: 패턴 매칭 기반 자동 알림
- **드릴다운**: 문제 지점에서 관련 데이터까지 연결

**C. 통합 모니터링 아키텍처:**

**데이터 수집:**
```
EKS Pods → FluentBit → OpenSearch (로그)
EKS Apps → OpenTelemetry → OpenSearch (트레이스)
```

**상관관계 분석:**
- **트레이스 ID 매칭**: 동일한 요청의 로그와 트레이스 연결
- **타임스탬프 기반**: 시간 범위로 관련 이벤트 그룹화
- **서비스 태그**: 마이크로서비스별 데이터 필터링

**D. 장애 지점 식별:**

**통합 관찰성:**
- **서비스 맵**: 마이크로서비스 간 호출 관계 시각화
- **오류 추적**: 실패한 요청의 전체 경로 추적
- **성능 분석**: 병목 지점과 응답 시간 분석

**실시간 모니터링:**
- **대시보드**: 실시간 서비스 상태 및 성능 메트릭
- **알림**: 임계값 위반이나 오류율 증가 시 즉시 알림
- **근본 원인 분석**: 문제 발생 시 관련 로그와 트레이스 자동 연결

---

### 13. 주문 처리 추적 시스템 - AWS Glue + Redshift + QuickSight

**문제 시나리오**: 이커머스 회사가 AWS에서 호스팅되는 여러 운영 시스템에 걸친 복잡한 주문 처리 프로세스를 운영함. 각 운영 시스템은 최신 처리 상태가 저장되는 JDBC 호환 관계형 데이터베이스를 보유함. 회사는 운영팀이 전체 주문 처리 과정에서 시간당 주문을 추적할 수 있는 기능을 제공해야 함.

**정답: A. Use AWS Glue to build ingestion pipelines from the operational systems into Amazon Redshift. Build dashboards in Amazon QuickSight that track the orders**

**A. 왜 이 솔루션이 최적인가:**

**최소 개발 오버헤드 (LEAST development overhead):**
- **완전 관리형**: AWS Glue, Redshift, QuickSight 모두 서버리스/관리형 서비스
- **기본 통합**: AWS 서비스 간 네이티브 통합으로 복잡한 설정 불필요
- **GUI 기반**: 코드 작성 최소화, 시각적 도구로 구성

**AWS Glue 장점:**
- **JDBC 연결**: 기존 관계형 데이터베이스와 직접 연결
- **ETL 자동화**: 스케줄 기반 자동 데이터 수집
- **스키마 추론**: 자동 스키마 감지 및 변환

**B. 통합 아키텍처:**

**데이터 수집:**
```
운영 시스템 DB (JDBC) → AWS Glue → Amazon Redshift
     ↓                      ↓            ↓
  주문 처리 상태         ETL 파이프라인    데이터 웨어하우스
```

**실시간 대시보드:**
- **QuickSight**: Redshift와 직접 연결
- **시간별 추적**: 주문 상태별 시간당 메트릭
- **전체 프로세스**: 여러 시스템의 데이터 통합 뷰

**C. 운영 추적 기능:**

**주문 상태 모니터링:**
- **실시간 현황**: 각 단계별 주문 수량 및 상태
- **병목 지점**: 처리 지연이 발생하는 시스템 식별
- **SLA 추적**: 처리 시간 목표 대비 실제 성과

**대시보드 구성:**
- **시간별 트렌드**: 주문량, 처리량, 완료율 추이
- **시스템별 분석**: 각 운영 시스템의 처리 성능
- **알림 설정**: 임계값 위반 시 자동 알림

**D. 확장성 및 유지보수:**

**데이터 파이프라인:**
- **증분 로드**: 변경된 데이터만 효율적으로 수집
- **오류 처리**: 실패한 ETL 작업 자동 재시도
- **모니터링**: CloudWatch를 통한 파이프라인 상태 추적

**비즈니스 연속성:**
- **백업**: Redshift 자동 백업으로 데이터 보호
- **확장**: 데이터 증가에 따른 자동 스케일링
- **보안**: IAM 기반 접근 제어 및 암호화

---

### 14. QuickSight 환율 계산 최적화 - Dataset Calculated Field with SPICE

**문제 시나리오**: 소매 회사가 전 세계적으로 사업을 확장하며, 재무 보고서를 위해 Amazon QuickSight에서 환율을 정확하게 계산해야 함. 글로벌 통화 값과 환율이 포함된 데이터셋 분석을 기반으로 한 시각화가 포함된 기존 대시보드가 있음. 데이터 엔지니어는 환율이 소수점 네 자리까지 정확하게 계산되도록 해야 하며, 계산은 사전 계산되어야 하고, QuickSight SPICE에서 결과를 구체화해야 함.

**정답: A. Define and create the calculated field in the dataset**

**A. 왜 Dataset Calculated Field가 최적인가:**

**사전 계산 (Precomputed) 요구사항 충족:**
- **Dataset 레벨**: 데이터 준비 단계에서 계산 수행
- **SPICE 저장**: 계산된 결과가 메모리에 미리 저장됨
- **쿼리 시 즉시 반환**: 대시보드 로드 시 추가 계산 불필요

**정밀도 보장:**
- **소수점 4자리**: DECIMAL 타입으로 정확한 환율 계산
- **일관성**: 모든 시각화에서 동일한 계산 로직 적용
- **데이터 품질**: 계산 오류 최소화

**B. SPICE 최적화:**

**인메모리 성능:**
- **빠른 응답**: 미리 계산된 환율이 메모리에 상주
- **병렬 처리**: SPICE 엔진의 병렬 계산 능력 최대 활용
- **캐싱**: 반복적인 쿼리에 대한 즉시 응답

**메모리 효율성:**
- **압축 저장**: 계산된 값의 효율적인 메모리 사용
- **인덱싱**: 빠른 데이터 액세스를 위한 자동 인덱싱
- **최적화**: QuickSight의 자동 성능 최적화

**C. 실제 구현 시나리오:**

**환율 계산 필드:**
- **기준 통화**: USD 대비 각국 통화 환율
- **정밀도**: 소수점 네 자리까지 정확한 계산
- **실시간 업데이트**: 데이터 새로고침 시 최신 환율 반영

**재무 보고서 활용:**
- **매출 환산**: 각국 매출을 기준 통화로 환산
- **수익 분석**: 지역별 수익성 정확한 계산
- **예산 계획**: 환율 변동을 고려한 예산 수립

**D. 글로벌 확장 지원:**

**다중 통화 지원:**
- **실시간 환율**: 최신 환율 데이터 자동 반영
- **지역별 분석**: 각 지역의 현지 통화 기준 분석
- **통합 보고**: 글로벌 통합 재무 보고서 생성

**확장성:**
- **새로운 시장**: 신규 진출 국가 통화 자동 추가
- **복합 계산**: 환율 기반 추가 비즈니스 메트릭 계산
- **데이터 거버넌스**: 일관된 환율 계산 기준 유지

---

### 15. 엔터프라이즈 데이터 카탈로그 구축 - AWS Glue Crawler와 Classifiers

**문제 시나리오**: 데이터 엔지니어가 회사의 Amazon S3 버킷과 Amazon RDS 데이터베이스를 기반으로 엔터프라이즈 데이터 카탈로그를 구축해야 함. 데이터 카탈로그에는 카탈로그 내 데이터의 저장 형식 메타데이터가 포함되어야 함.

**정답: B. Use an AWS Glue crawler to build a data catalog. Use AWS Glue crawler classifiers to recognize the format of data and store the format in the catalog**

**A. 왜 AWS Glue Crawler가 최적인가:**

**최소 노력 (LEAST effort) 달성:**
- **자동화된 발견**: S3와 RDS의 모든 데이터 자동 스캔
- **스키마 추론**: 데이터 구조와 타입 자동 감지
- **메타데이터 생성**: 테이블 정의와 파티션 정보 자동 생성

**통합 데이터 소스 지원:**
- **S3 버킷**: 다양한 파일 형식 (Parquet, JSON, CSV, Avro 등)
- **RDS 데이터베이스**: 관계형 데이터베이스 테이블 구조
- **단일 인터페이스**: 하나의 도구로 이기종 데이터 소스 처리

**B. Glue Crawler Classifiers의 역할:**

**저장 형식 인식:**
- **기본 Classifiers**: CSV, JSON, Avro, Parquet, ORC 등 자동 인식
- **커스텀 Classifiers**: 고유한 데이터 형식에 대한 사용자 정의 규칙
- **우선순위 처리**: 여러 형식이 감지될 때 우선순위에 따른 처리

**메타데이터 저장:**
- **형식 정보**: 파일 형식, 압축 타입, 인코딩 정보
- **스키마 정보**: 컬럼명, 데이터 타입, 제약 조건
- **파티션 정보**: 디렉토리 구조 기반 파티셔닝 스키마

**C. 엔터프라이즈 데이터 카탈로그 구성:**

**중앙집중식 메타데이터:**
- **통합 뷰**: 모든 데이터 자산의 단일 카탈로그
- **검색 기능**: 데이터 자산의 빠른 검색 및 발견
- **리니지 추적**: 데이터 출처와 변환 이력 관리

**자동 업데이트:**
- **스케줄링**: 정기적인 크롤링으로 메타데이터 최신 유지
- **증분 업데이트**: 변경된 데이터만 효율적으로 처리
- **버전 관리**: 스키마 변경 이력 추적

**D. 실제 활용 시나리오:**

**데이터 거버넌스:**
- **데이터 품질**: 스키마 일관성 검증
- **규정 준수**: 데이터 분류 및 보안 태그
- **접근 제어**: 테이블별 권한 관리

**분석 및 BI:**
- **Athena 통합**: 카탈로그 기반 SQL 쿼리
- **QuickSight 연결**: 시각화 도구와 직접 연동
- **EMR 활용**: 빅데이터 분석 워크로드 지원

**운영 효율성:**
- **자동 발견**: 새로운 데이터 소스 자동 감지
- **표준화**: 일관된 메타데이터 형식
- **셀프 서비스**: 데이터 사용자의 자율적 데이터 탐색

---

