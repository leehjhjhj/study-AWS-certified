## 1010 (DEA-C01)

### Redshift 크로스 리전 스냅샷 복사 - KMS 암호화 구성

**문제 시나리오**: AWS KMS로 암호화된 Amazon Redshift 클러스터를 보유. 재해 복구(DR) 전략의 일환으로 크로스 리전 스냅샷을 구성해야 함. AWS CLI를 사용하여 크로스 리전 스냅샷 생성 필요.

**정답: B. In the source AWS Region, enable snapshot copying. Specify the name of the snapshot copy grant that is created in the destination AWS Region + D. Create a KMS key and configure a snapshot copy grant in the destination AWS Region**

**이유:**

**크로스 리전 스냅샷 복사 프로세스:**

1. **목적지 리전에서 준비 (D):**
   - 목적지 리전에서 새로운 KMS 키 생성
   - Snapshot Copy Grant 생성: Redshift가 목적지 리전에서 KMS 키를 사용하여 스냅샷을 암호화할 수 있도록 권한 부여
   - 리전 간 복사 시 소스 리전의 KMS 키를 직접 사용할 수 없기 때문에 필수

2. **소스 리전에서 활성화 (B):**
   - 소스 리전에서 스냅샷 복사 기능 활성화
   - 목적지 리전에서 생성한 Snapshot Copy Grant의 이름 지정
   - Redshift가 자동으로 스냅샷을 목적지 리전으로 복사하고 목적지 KMS 키로 재암호화

**Snapshot Copy Grant:**
- Redshift가 크로스 리전 복사 시 KMS 키를 사용할 수 있도록 하는 권한 객체
- 리전별로 독립적인 KMS 키를 사용하기 때문에 필수
- 보안: 각 리전의 KMS 키로 독립적으로 암호화하여 보안 강화

**틀린 답:**

**A와 C - 소스 리전의 Snapshot Copy Grant:**
- 크로스 리전 복사에서는 목적지 리전의 Grant가 필요함
- 소스 리전의 KMS 키는 리전 경계를 넘어 사용할 수 없음
- 스냅샷은 목적지 리전의 KMS 키로 재암호화되어야 함

**E. Multi-AZ deployment:**
- Multi-AZ는 가용 영역(AZ) 레벨의 고가용성 제공
- 크로스 리전 DR 요구사항과 무관
- 스냅샷 복사 문제를 해결하지 못함

---

### 데이터 카탈로그 - Amazon DataZone으로 비즈니스 메타데이터 관리

**문제 시나리오**: 데이터 레이크와 데이터 웨어하우스 보유. 데이터 카탈로그에 비즈니스 메타데이터와 용어집(glossary) 정보를 모든 자산에 추가할 수 있는 기능 필요. 최소 운영 오버헤드로 구현 필요.

**정답: C. Use Amazon DataZone. Create the business glossaries. Create metadata forms. Use the Amazon DataZone data portal to access the metadata**

**이유:**

**Amazon DataZone의 장점:**
- **통합 데이터 카탈로그**: 비즈니스 용어집과 메타데이터를 네이티브로 지원
- **메타데이터 폼**: 커스텀 비즈니스 메타데이터를 구조화된 형태로 정의 및 관리
- **데이터 포털**: 별도 웹 애플리케이션 개발 없이 즉시 사용 가능한 UI 제공
- **관리형 서비스**: 인프라 관리 불필요, 자동 스케일링
- **거버넌스**: 데이터 자산에 대한 접근 제어 및 승인 워크플로우 내장

**틀린 답:**

**A. AWS Glue Catalog + 커스텀 웹 앱:**
- API를 통한 수동 메타데이터 관리로 복잡성 증가
- 별도 웹 애플리케이션 개발 및 유지보수 필요
- 비즈니스 용어집 기능이 네이티브로 제공되지 않음

**B. Apache Hive metastore:**
- 자체 호스팅 필요로 운영 오버헤드 큼
- 비즈니스 메타데이터 관리 기능 제한적
- 웹 애플리케이션 별도 구축 필요

**D. Amazon OpenSearch Service:**
- 검색 엔진으로 데이터 카탈로그 목적에 최적화되지 않음
- 인덱스 관리 및 스키마 설계 필요
- 비즈니스 용어집 기능 직접 구현 필요

---

### 데이터 품질 검사 - AWS Glue Data Quality Evaluation Transform

**문제 시나리오**: BI 리포트용 데이터 파이프라인에서 데이터 누락 발생. 스토리지에 저장하기 전 단계에서 null 값 검사 및 참조 무결성(referential integrity) 검사 필요. 최소 운영 오버헤드로 구현 필요.

**정답: B. Use AWS Glue ETL jobs to perform a data quality evaluation transform on the data. Use an IsComplete rule on the requested columns. Use a ReferentialIntegrity rule for each join**

**이유:**

**AWS Glue Data Quality Evaluation Transform:**
- **내장 규칙**: IsComplete, ReferentialIntegrity 등 사전 정의된 규칙 제공
- **ETL 통합**: 기존 Glue ETL 파이프라인에 바로 추가 가능
- **선언적 규칙**: 복잡한 SQL이나 코드 작성 없이 규칙 설정
- **자동 보고**: 데이터 품질 결과를 자동으로 로깅 및 모니터링

**IsComplete 규칙:**
- 지정된 컬럼에 null 값이 없는지 자동 확인
- 컬럼 레벨 완전성 검증

**ReferentialIntegrity 규칙:**
- 조인 시 외래 키 관계 자동 검증
- 참조 무결성 보장

**틀린 답:**

**A와 D. SageMaker Data Wrangler:**
- 대화형 데이터 준비 도구로 프로덕션 파이프라인에 부적합
- ETL 파이프라인 통합이 복잡함
- 지속적인 데이터 품질 모니터링에 최적화되지 않음

**C. SQL Transform:**
- 각 규칙을 수동으로 SQL로 작성해야 함
- 유지보수 어려움, 확장성 낮음
- 데이터 품질 결과 추적 및 보고 기능 부족

---

### PII 데이터 접근 제어 - AWS Lake Formation 컬럼 레벨 권한

**문제 시나리오**: JSON 파일에 PII 데이터와 non-PII 데이터 혼재. non-PII 데이터는 전체 직원 접근 가능, PII 데이터는 제한된 그룹만 접근 가능. 쿼리 및 분석 가능하도록 구성 필요. 최소 운영 오버헤드로 구현.

**정답: C. Store the JSON file in an Amazon S3 bucket. Catalog the file schema in AWS Lake Formation. Use Lake Formation permissions to provide access to the required data based on the type of user**

**이유:**

**AWS Lake Formation의 장점:**
- **컬럼 레벨 권한**: 동일 테이블 내 특정 컬럼(PII)에 대한 세분화된 접근 제어
- **중앙 집중식 관리**: 단일 위치에서 모든 데이터 접근 권한 관리
- **데이터 카탈로그 통합**: Glue Catalog를 통한 자동 스키마 관리
- **쿼리 엔진 통합**: Athena, Redshift Spectrum, EMR 등에서 동일한 권한 적용
- **파일 분리 불필요**: 원본 데이터 유지하면서 논리적 접근 제어

**사용자 그룹별 권한:**
- 일반 직원: non-PII 컬럼만 SELECT 권한
- 제한 그룹: 모든 컬럼(PII 포함) SELECT 권한

**틀린 답:**

**A. Glue로 파일 분리:**
- 데이터 중복 저장으로 스토리지 비용 증가
- 파일 분리 ETL 작업 지속 실행 필요
- 데이터 동기화 문제 발생 가능

**B. Amazon Macie:**
- PII 탐지 및 모니터링 도구로 접근 제어 기능 없음
- 별도 권한 관리 메커니즘 필요

**D. RDS PostgreSQL:**
- S3 기반 데이터 레이크 아키텍처에 부적합
- JSON 대용량 파일 로딩 복잡
- 데이터베이스 관리 오버헤드 높음

---

### AWS Glue Data Quality - ReferentialIntegrity 규칙

**문제 시나리오**: 두 데이터셋(reference, primary) 보유. primary 데이터셋의 city와 state 컬럼 값이 reference 데이터셋의 특정 값과 정확히 일치하는지 확인 필요. AWS Glue Data Quality의 DQDL 규칙 사용.

**정답: B. ReferentialIntegrity "city,state" "reference.{ref_city,ref_state}" = 1.0**

**이유:**

**ReferentialIntegrity 규칙:**
- **참조 무결성 검증**: primary 데이터셋의 값이 reference 데이터셋에 모두 존재하는지 확인
- **복합 키 지원**: 여러 컬럼(city, state) 조합으로 참조 관계 검증
- **임계값 1.0**: 100% 일치 요구 (모든 레코드가 reference에 존재해야 함)
- **외래 키 검증**: 데이터베이스의 외래 키 제약조건과 유사한 검증

**구문 설명:**
- `"city,state"`: primary 데이터셋의 검증 대상 컬럼
- `"reference.{ref_city,ref_state}"`: reference 데이터셋의 참조 컬럼
- `= 1.0`: 100% 일치율 요구

**틀린 답:**

**A와 C. DatasetMatch:**
- 두 데이터셋 전체를 비교하는 규칙
- 특정 컬럼의 참조 무결성이 아닌 전체 데이터셋 일치 여부 확인
- 요구사항의 "특정 값이 존재하는지" 확인에 부적합

**D. 임계값 100:**
- DQDL의 임계값은 0.0~1.0 범위 (백분율이 아닌 비율)
- 100은 유효하지 않은 값

---

### Redshift 스트리밍 수집 - Materialized View로 MSK 연동

**문제 시나리오**: Amazon MSK에서 Redshift 데이터 웨어하우스로 스트리밍 데이터 수집 필요. 낮은 데이터 접근 시간과 스토리지 비용 최적화 필요. 최소 운영 오버헤드로 구현.

**정답: A. Create an external schema that maps to the MSK cluster. Create a materialized view that references the external schema to consume the streaming data from the MSK topic**

**이유:**

**Redshift Streaming Ingestion:**
- **직접 연동**: MSK에서 Redshift로 직접 스트리밍 수집 (중간 스토리지 불필요)
- **External Schema**: MSK 토픽을 외부 스키마로 매핑
- **Materialized View**: 스트리밍 데이터를 자동으로 Redshift 테이블로 변환 및 저장
- **자동 새로고침**: MV가 주기적으로 새 데이터를 MSK에서 가져와 업데이트

**낮은 접근 시간:**
- 데이터가 Redshift 로컬 스토리지에 저장됨
- 쿼리 시 직접 접근 가능 (외부 조회 불필요)

**스토리지 비용 최적화:**
- S3 중간 저장소 불필요
- Redshift 압축 및 컬럼 스토리지 활용

**틀린 답:**

**B. Glue Streaming ETL + Redshift Spectrum:**
- S3 중간 스토리지 비용 발생
- Spectrum 쿼리는 로컬 데이터보다 느림
- Glue 스트리밍 작업 운영 오버헤드

**C. External Schema + Redshift Table:**
- External schema만으로는 실시간 데이터 수집 불가
- Materialized View 없이 자동 데이터 로딩 불가능

**D. S3 + Lambda:**
- Lambda 동시성 제한으로 스트리밍 처리에 부적합
- S3 중간 저장소 필요로 복잡도 증가
- 이벤트 기반 처리로 지연 발생 가능

---

### S3에서 Redshift로 ETL - Lambda + EventBridge로 자동화

**문제 시나리오**: 40~60분마다 S3 버킷에 CSV 파일 수신 (100KB~300KB). 각 파일 내용을 Redshift로 ETL 파이프라인 구성 필요. 최소 운영 오버헤드로 구현.

**정답: A. Create an AWS Lambda function that connects to Amazon Redshift and runs a COPY command. Use Amazon EventBridge to invoke the Lambda function based on an Amazon S3 upload trigger**

**이유:**

**Lambda + COPY 명령:**
- **서버리스**: 인프라 관리 불필요
- **COPY 명령**: Redshift의 네이티브 대량 로딩 명령으로 최적화된 성능
- **소량 파일**: 100-300KB 크기는 Lambda 실행 시간 내 처리 가능
- **간단한 로직**: CSV를 그대로 로딩하므로 복잡한 변환 불필요

**EventBridge (S3 이벤트):**
- **자동 트리거**: S3 파일 업로드 시 자동으로 Lambda 실행
- **이벤트 기반**: 파일 도착 즉시 처리
- **비용 효율**: 파일이 있을 때만 실행

**틀린 답:**

**B. Kinesis Data Firehose:**
- Firehose는 스트리밍 데이터용으로 설계됨
- Lambda를 source로 사용하는 것은 비정형적
- S3에서 데이터를 pull하는 것은 Firehose의 일반적 사용 패턴 아님

**C. Redshift Spectrum:**
- Spectrum은 S3 데이터를 직접 쿼리 (로딩하지 않음)
- 요구사항은 Redshift 테이블로 "업로드"이므로 부적합
- 쿼리 성능이 로컬 테이블보다 낮음

**D. AWS DMS:**
- DMS는 데이터베이스 간 마이그레이션 도구
- S3 CSV 파일 처리에 과도하게 복잡함
- 지속적인 복제 작업 관리 오버헤드

---

### S3 Dimension Table 업데이트 - Apache Hudi로 최적화

**문제 시나리오**: S3에 dimension table 구축. 1TB 크기의 1천만 레코드 히스토리 데이터 보유. 매일 최대 1만 개 레코드 업데이트 필요. 최저 런타임으로 구현.

**정답: D. Develop an Amazon EMR job to read new changes into Apache Spark DataFrames. Use the Apache Hudi framework to create the base table in Amazon S3. Use the Spark update method to update the base table**

**이유:**

**Apache Hudi의 장점:**
- **증분 업데이트**: 전체 데이터를 읽지 않고 변경된 레코드만 업데이트
- **ACID 트랜잭션**: S3에서 원자적 업데이트 보장
- **Copy-on-Write**: 업데이트 시 변경된 파일만 재작성
- **인덱싱**: 빠른 레코드 조회를 위한 자동 인덱싱

**런타임 최적화:**
- 1TB 전체 읽기 불필요 (변경 레코드만 처리)
- 파티션 프루닝으로 필요한 파일만 접근
- Upsert 최적화로 빠른 업데이트

**EMR 활용:**
- Hudi 네이티브 지원
- Spark 분산 처리로 대용량 데이터 효율적 처리

**틀린 답:**

**A와 C. 일반 Spark update:**
- 전체 1TB 데이터를 읽어야 함 (매우 느림)
- 업데이트 후 전체 데이터를 재작성해야 함
- 증분 업데이트 최적화 없음

**B. Glue Python + Pandas:**
- Pandas는 인메모리 처리로 1TB 데이터에 부적합
- 단일 노드 처리로 성능 매우 낮음
- 분산 처리 불가능

---

### Glue ETL 디스크 공간 부족 - Data Skew 해결

**문제 시나리오**: AWS Glue Spark ETL 작업 실행 시 "No space left on device" 오류 발생. 오류 원인 식별 및 해결 필요. 최소 비용으로 구현.

**정답: B. Use the Spark UI and AWS Glue metrics to monitor data skew in the Spark executors + D. Enable the --write-shuffle-files-to-s3 job parameter. Use the salting technique**

**이유:**

**B. Spark UI로 데이터 스큐 모니터링:**
- **원인 진단**: "No space left" 오류는 일반적으로 데이터 스큐로 인해 특정 executor의 로컬 디스크 부족 발생
- **Spark UI**: executor별 데이터 분포 시각화
- **Glue Metrics**: 스큐가 발생한 작업 및 파티션 식별
- **비용 없음**: 모니터링 도구 사용에 추가 비용 불필요

**D. Shuffle 파일을 S3로 이동 + Salting:**
- **--write-shuffle-files-to-s3**: Shuffle 중간 파일을 로컬 디스크 대신 S3에 저장
- **디스크 공간 확보**: executor 로컬 디스크 사용량 감소
- **Salting**: 스큐된 키에 랜덤 값 추가로 데이터 균등 분산
- **근본 해결**: 스큐 문제 자체를 해결

**틀린 답:**

**A. 수직 확장 (Vertical scaling):**
- 각 워커의 리소스 증가로 비용 상승
- 스큐 문제의 근본 원인 미해결
- 비용 효율적이지 않음

**C. 수평 확장 (Horizontal scaling):**
- 워커 수 증가로 비용 상승
- 스큐된 데이터는 여전히 특정 executor에 집중
- 문제 해결 안 됨

**E. CloudWatch 로그:**
- 로그만으로는 executor별 데이터 분포 파악 어려움
- Spark UI가 더 상세한 정보 제공
- 근본 원인 분석에 부적합

---

### Redshift에서 S3로 데이터 전송 - UNLOAD 명령

**문제 시나리오**: Redshift 데이터 웨어하우스에 벤더 데이터 저장. 매주 벤더의 S3 버킷으로 해당 데이터 전송 필요.

**정답: B. Create an AWS Glue job to connect to the Redshift data warehouse. Configure the AWS Glue job to use the Redshift UNLOAD command to load the required data to the vendor's S3 bucket on a schedule**

**이유:**

**UNLOAD 명령:**
- **Redshift → S3 전용**: 데이터를 S3로 내보내기 위해 최적화된 명령
- **병렬 처리**: 여러 파일로 분산하여 빠른 언로드
- **압축 지원**: GZIP, BZIP2 등으로 전송 크기 최소화
- **파티셔닝**: 컬럼별로 데이터 분할 가능

**AWS Glue Job:**
- **스케줄링**: 크론 표현식으로 주간 실행 설정
- **관리형**: 서버리스로 인프라 관리 불필요
- **Redshift 통합**: JDBC 연결로 쉽게 UNLOAD 실행

**틀린 답:**

**A. Lambda + COPY 명령:**
- **COPY는 S3 → Redshift** 방향 (반대 방향)
- UNLOAD가 아닌 COPY는 데이터 내보내기 불가능
- 명령어 사용 오류

**C. Redshift Data Sharing:**
- Data Sharing은 Redshift 클러스터 간 데이터 공유 기능
- S3 버킷으로 데이터 전송 불가능
- 실시간 쿼리 공유용이지 파일 전송용 아님

**D. Redshift Spectrum:**
- Spectrum은 S3 데이터를 쿼리하는 기능 (읽기 전용)
- S3로 데이터를 쓰는 기능 없음
- 양방향 쿼리는 존재하지 않음

---

### Glue ETL 소형 파일 성능 개선 - DynamicFrame Grouping

**문제 시나리오**: 시간당 S3에 200-300KB 파일 생성. 5년간 44,000개 파일 축적. 최소 워커로 두 번째 Glue ETL 파이프라인 구축했으나 성능 문제 발생. 최소 비용으로 성능 개선 필요.

**정답: C. Use the AWS Glue DynamicFrame grouping option**

**이유:**

**소형 파일 문제 (Small File Problem):**
- 44,000개의 작은 파일은 파일 메타데이터 처리로 오버헤드 발생
- 각 파일마다 S3 API 호출 및 파티션 생성으로 성능 저하
- Spark는 대용량 파일에 최적화됨

**DynamicFrame Grouping:**
- **파일 그룹화**: 여러 소형 파일을 논리적으로 그룹화하여 처리
- **파티션 최적화**: 적절한 크기의 파티션으로 재구성
- **메타데이터 오버헤드 감소**: S3 리스팅 및 파일 열기 횟수 최소화
- **비용 추가 없음**: 워커 수나 타입 변경 없이 성능 향상

**groupFiles 옵션:**
- inPartition: 파티션 내 파일 그룹화
- 대용량 블록으로 읽어 처리 효율 극대화

**틀린 답:**

**A. 더 큰 워커 타입:**
- 비용 증가
- 소형 파일 문제의 근본 원인 미해결
- CPU/메모리 증가만으로는 I/O 병목 개선 불가

**B. 워커 수 증가:**
- 비용 증가
- 오히려 더 많은 파티션 생성으로 성능 악화 가능
- 소형 파일에 더 많은 병렬 처리는 비효율적

**D. Auto Scaling:**
- 비용 증가
- 워커 자동 조정이지만 소형 파일 문제 해결 안 됨
- 불필요한 스케일링으로 비용만 상승

---

### Athena 쿼리 최적화 - 파티션 필터 적용

**문제 시나리오**: Athena 노트북에서 Apache Spark로 S3의 대용량 파티션 데이터 분석. Glue Crawler가 파티션 업데이트. 스캔 데이터량을 최소화하여 Athena 쿼리 효율성 향상 필요.

**정답: A. Apply partition filters in the queries**

**이유:**

**파티션 필터의 효과:**
- **파티션 프루닝**: WHERE 절에 파티션 키 조건 추가로 불필요한 파티션 스캔 제외
- **스캔 데이터 감소**: 관련 파티션만 읽어 I/O 및 비용 절감
- **쿼리 성능 향상**: 처리할 데이터량 감소로 실행 시간 단축
- **비용 절감**: Athena는 스캔한 데이터량에 따라 과금

**파티션 필터 예시:**
- `WHERE year=2024 AND month=01`: 특정 연월 파티션만 스캔
- 파티션 키를 쿼리 조건에 명시적으로 포함

**틀린 답:**

**B. Crawler 빈도 증가:**
- 파티션 메타데이터 업데이트 빈도만 높임
- 쿼리 시 스캔 데이터량에 영향 없음
- 오히려 Crawler 비용만 증가

**C. 중첩 디렉토리 구조:**
- 데이터 구조 변경은 대규모 재작업 필요
- 이미 파티션되어 있으므로 추가 효과 제한적
- 쿼리 성능에 직접적 영향 적음

**D. Spark 인메모리 캐싱:**
- Athena 쿼리 실행 시점에 메모리 캐시 유지 불가
- 노트북 세션 종료 시 캐시 손실
- S3 데이터 스캔량 자체를 줄이지 못함

---

### Glue Job 스테이지 메트릭 분석 - Spark UI 활용

**문제 시나리오**: AWS Glue Spark ETL 작업 실패. 작업 내 모든 개별 스테이지의 메트릭 조사 필요. 로깅 및 모니터링 활성화 상태.

**정답: A. Examine the AWS Glue job and stage details in the Spark UI**

**이유:**

**Spark UI의 상세 정보:**
- **스테이지별 메트릭**: 각 스테이지의 실행 시간, 태스크 수, 데이터 처리량 확인
- **DAG 시각화**: 작업의 Directed Acyclic Graph로 스테이지 간 의존성 파악
- **Executor 메트릭**: CPU, 메모리, 디스크 사용량, 셔플 데이터량
- **태스크 레벨 상세**: 개별 태스크 성공/실패, 지연 시간, 데이터 스큐
- **SQL 탭**: DataFrame/SQL 쿼리 실행 계획 및 성능

**Glue에서 Spark UI 접근:**
- Glue Console에서 작업 실행 세부 정보에서 "Spark UI" 링크 클릭
- 히스토리 서버를 통해 완료된 작업도 분석 가능

**틀린 답:**

**B. CloudWatch 메트릭:**
- Job 레벨 메트릭만 제공 (전체 CPU, 메모리 등)
- 개별 스테이지별 상세 메트릭 없음
- 스테이지 간 성능 비교 불가능

**C. CloudTrail 로그:**
- API 호출 감사 로그 (Glue 작업 시작/중지 등)
- 작업 내부 실행 메트릭 포함 안 함
- 스테이지 성능 데이터 없음

**D. Run Insights:**
- 작업 레벨의 고수준 인사이트 제공
- 스테이지별 상세 메트릭 제공 안 함
- Spark UI보다 덜 상세함

---